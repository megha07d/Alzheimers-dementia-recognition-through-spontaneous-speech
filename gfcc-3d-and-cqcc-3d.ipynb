{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Spafe python package**\n* using this we can get CQCC,GFCC,MFCC, many useful audio features","metadata":{}},{"cell_type":"code","source":"!pip install -U spafe","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:07.139662Z","iopub.execute_input":"2023-06-15T08:58:07.140043Z","iopub.status.idle":"2023-06-15T08:58:20.374364Z","shell.execute_reply.started":"2023-06-15T08:58:07.140016Z","shell.execute_reply":"2023-06-15T08:58:20.372271Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting spafe\n  Downloading spafe-0.3.2-py3-none-any.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from spafe) (1.23.5)\nRequirement already satisfied: scipy>=1.7.3 in /opt/conda/lib/python3.10/site-packages (from spafe) (1.10.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from spafe) (4.5.0)\nInstalling collected packages: spafe\nSuccessfully installed spafe-0.3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# load audio\nimport librosa\n\n# get MFCC coefs\nfrom spafe.features.mfcc import mfcc\n\n# get GFCC coefs\nfrom spafe.features.gfcc import gfcc\n\n# get CQCC coefs\nfrom spafe.features.cqcc import cqcc\n\n# concat , stack into 3d\nimport numpy as np\n\n# progress\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:20.377045Z","iopub.execute_input":"2023-06-15T08:58:20.377434Z","iopub.status.idle":"2023-06-15T08:58:21.095956Z","shell.execute_reply.started":"2023-06-15T08:58:20.377398Z","shell.execute_reply":"2023-06-15T08:58:21.094771Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## **Extract MFCC's**","metadata":{}},{"cell_type":"code","source":"def extract_3d_mfcc(audio_path):  \n\n    # get audio\n    waveform, sample_rate = librosa.load(audio_path)\n\n    # # play audio\n    # IPython.display.Audio(data=waveform,rate = sample_rate)\n    \n    # extract mfcc\n    mfccs = mfcc(sig = waveform,fs = sample_rate,num_ceps=20)\n    \n    # print(mfccs.shape)\n    \n    # extract delta mfcc\n    delta_mfcc = librosa.feature.delta(mfccs,order=1)\n\n    # extract delta-delta mfcc\n    delta_delta_mfcc = librosa.feature.delta(mfccs,order=2)\n    \n    ## concatenate features along feature axis - along row - subject to change\n    #mfcc_features = np.concatenate((mfccs,delta_mfcc,delta_delta_mfcc),axis = 0)\n    \n    # send three features\n    mfcc_features = [mfccs,delta_mfcc,delta_delta_mfcc]\n    \n    \n    # print(mfccs.shape)\n    \n    return mfcc_features\n\nextract_3d_mfcc('/kaggle/input/dementia-audio-classification/adrso_002_2_cn.wav')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:21.108149Z","iopub.execute_input":"2023-06-15T08:58:21.108548Z","iopub.status.idle":"2023-06-15T08:58:32.544317Z","shell.execute_reply.started":"2023-06-15T08:58:21.108511Z","shell.execute_reply":"2023-06-15T08:58:32.543035Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[array([[-4.23080335e+01,  1.71486552e+00, -2.98491247e+00, ...,\n         -4.53709906e-01, -9.97687125e-01,  2.01303435e-01],\n        [-4.33348367e+01,  3.99063817e+00, -5.08493513e+00, ...,\n         -9.01124535e-01, -4.55478961e-01,  3.04762393e-01],\n        [-4.38325446e+01,  5.44536089e+00, -6.63221917e+00, ...,\n         -8.50285201e-01, -3.70703214e-01, -2.80809776e-01],\n        ...,\n        [-1.07213196e+02, -2.16751769e+00,  7.49229282e+00, ...,\n         -4.55624494e-01, -5.86214515e-01, -5.56203386e-01],\n        [-1.09167199e+02, -4.89846960e+00,  3.32845806e+00, ...,\n         -5.82401021e-01, -2.48299176e-01, -2.95282175e-01],\n        [-1.13901865e+02, -4.35148079e+00,  3.77198233e-02, ...,\n         -8.21546975e-01, -6.22274957e-01, -6.77371322e-01]]),\n array([[ 2.37852362e+00,  2.37852362e+00,  2.37852362e+00, ...,\n         -1.57475594e-02, -1.57475594e-02, -1.57475594e-02],\n        [ 2.46663342e+00,  2.46663342e+00,  2.46663342e+00, ...,\n          1.38395504e-01,  1.38395504e-01,  1.38395504e-01],\n        [ 2.51808752e+00,  2.51808752e+00,  2.51808752e+00, ...,\n          9.86519531e-02,  9.86519531e-02,  9.86519531e-02],\n        ...,\n        [ 6.97429264e+00,  6.97429264e+00,  6.97429264e+00, ...,\n         -6.74670353e-03, -6.74670353e-03, -6.74670353e-03],\n        [ 7.41833303e+00,  7.41833303e+00,  7.41833303e+00, ...,\n          1.88634307e-02,  1.88634307e-02,  1.88634307e-02],\n        [ 7.90250289e+00,  7.90250289e+00,  7.90250289e+00, ...,\n         -7.91742021e-02, -7.91742021e-02, -7.91742021e-02]]),\n array([[-2.26377333, -2.26377333, -2.26377333, ...,  0.04186185,\n          0.04186185,  0.04186185],\n        [-2.25866295, -2.25866295, -2.25866295, ..., -0.03400497,\n         -0.03400497, -0.03400497],\n        [-2.19158159, -2.19158159, -2.19158159, ..., -0.02772582,\n         -0.02772582, -0.02772582],\n        ...,\n        [-7.06621404, -7.06621404, -7.06621404, ..., -0.04746112,\n         -0.04746112, -0.04746112],\n        [-7.10878155, -7.10878155, -7.10878155, ..., -0.01640007,\n         -0.01640007, -0.01640007],\n        [-7.04866218, -7.04866218, -7.04866218, ...,  0.0380192 ,\n          0.0380192 ,  0.0380192 ]])]"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Extract GFCC's**","metadata":{}},{"cell_type":"code","source":"def extract_3d_gfcc(audio_path):  \n\n    # get audio\n    waveform, sample_rate = librosa.load(audio_path)\n\n    # # play audio\n    # IPython.display.Audio(data=waveform,rate = sample_rate)\n    \n    # extract mfcc\n    gfccs = gfcc(sig = waveform,fs = sample_rate,num_ceps=20)\n    \n    # print(mfccs.shape)\n    \n    # extract delta mfcc\n    delta_gfcc = librosa.feature.delta(gfccs,order=1)\n\n    # extract delta-delta mfcc\n    delta_delta_gfcc = librosa.feature.delta(gfccs,order=2)\n    \n    ## concatenate features along feature axis - along row - subject to change\n    #gfcc_features = np.concatenate((gfccs,delta_gfcc,delta_delta_gfcc),axis = 0)\n\n    # send three features\n    gfcc_features = [gfccs,delta_gfcc,delta_delta_gfcc]\n    \n#     print(gfccs.shape)\n    \n    return gfcc_features\n\nextract_3d_gfcc('/kaggle/input/dementia-audio-classification/adrso_002_2_cn.wav')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:32.552171Z","iopub.execute_input":"2023-06-15T08:58:32.557777Z","iopub.status.idle":"2023-06-15T08:58:32.684793Z","shell.execute_reply.started":"2023-06-15T08:58:32.557704Z","shell.execute_reply":"2023-06-15T08:58:32.683539Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[array([[ 3.42137999e-01, -3.39146380e-02, -1.13869840e-01, ...,\n         -1.43911749e-03, -3.05625704e-02, -7.21332797e-05],\n        [ 3.45858631e-01, -3.79514528e-02, -1.55798570e-01, ...,\n          5.82925293e-03, -2.89148420e-02, -1.98135175e-02],\n        [ 3.69243689e-01, -4.47922674e-02, -1.84474733e-01, ...,\n         -1.93981951e-05, -2.03571928e-02, -1.74424221e-02],\n        ...,\n        [ 4.29524052e-03,  1.76466460e-04,  1.78359196e-03, ...,\n         -3.52207506e-04, -2.76699577e-04, -3.25114682e-04],\n        [ 3.10517439e-03, -9.82018308e-04,  1.01024344e-03, ...,\n         -7.46458792e-05, -9.13181782e-05, -1.51364867e-04],\n        [ 2.07716439e-03, -7.83590863e-04,  2.75267704e-04, ...,\n          1.58765457e-05, -8.74585613e-06, -5.35140268e-05]]),\n array([[-1.29694528e-02, -1.29694528e-02, -1.29694528e-02, ...,\n         -3.22085691e-03, -3.22085691e-03, -3.22085691e-03],\n        [-1.56613901e-02, -1.56613901e-02, -1.56613901e-02, ...,\n         -3.00228458e-03, -3.00228458e-03, -3.00228458e-03],\n        [-1.69052080e-02, -1.69052080e-02, -1.69052080e-02, ...,\n         -3.34252741e-03, -3.34252741e-03, -3.34252741e-03],\n        ...,\n        [-4.83841306e-04, -4.83841306e-04, -4.83841306e-04, ...,\n         -1.20035680e-04, -1.20035680e-04, -1.20035680e-04],\n        [-2.37333654e-04, -2.37333654e-04, -2.37333654e-04, ...,\n         -5.46013882e-05, -5.46013882e-05, -5.46013882e-05],\n        [-1.17918081e-04, -1.17918081e-04, -1.17918081e-04, ...,\n         -2.05464956e-05, -2.05464956e-05, -2.05464956e-05]]),\n array([[ 2.54155446e-02,  2.54155446e-02,  2.54155446e-02, ...,\n         -1.04481375e-03, -1.04481375e-03, -1.04481375e-03],\n        [ 2.27646412e-02,  2.27646412e-02,  2.27646412e-02, ...,\n         -1.96345429e-03, -1.96345429e-03, -1.96345429e-03],\n        [ 2.28275431e-02,  2.28275431e-02,  2.28275431e-02, ...,\n         -8.97977508e-04, -8.97977508e-04, -8.97977508e-04],\n        ...,\n        [ 3.13495696e-04,  3.13495696e-04,  3.13495696e-04, ...,\n         -2.28863055e-05, -2.28863055e-05, -2.28863055e-05],\n        [ 1.81427821e-04,  1.81427821e-04,  1.81427821e-04, ...,\n         -1.35624915e-05, -1.35624915e-05, -1.35624915e-05],\n        [ 1.06121981e-04,  1.06121981e-04,  1.06121981e-04, ...,\n         -8.55233964e-07, -8.55233964e-07, -8.55233964e-07]])]"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Extract CQCC's**","metadata":{}},{"cell_type":"code","source":"def extract_3d_cqcc(audio_path):  \n\n    # get audio\n    waveform, sample_rate = librosa.load(audio_path)\n\n    # # play audio\n    # IPython.display.Audio(data=waveform,rate = sample_rate)\n    \n    # extract mfcc\n    cqccs = cqcc(sig = waveform,fs = sample_rate,num_ceps=20)\n    \n    # print(mfccs.shape)\n    \n    # extract delta mfcc\n    delta_cqcc = librosa.feature.delta(cqccs,order=1)\n\n    # extract delta-delta mfcc\n    delta_delta_cqcc = librosa.feature.delta(cqccs,order=2)\n    \n    ## concatenate features along feature axis - along row - subject to change\n    #cqcc_features = np.concatenate((cqccs,delta_cqcc,delta_delta_cqcc),axis = 0)\n    \n    # send three features\n    cqcc_features = [cqccs,delta_cqcc,delta_delta_cqcc]\n    \n#     print(cqccs.shape)\n    \n    return cqcc_features\n\nextract_3d_cqcc('/kaggle/input/dementia-audio-classification/adrso_002_2_cn.wav')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:32.692785Z","iopub.execute_input":"2023-06-15T08:58:32.697678Z","iopub.status.idle":"2023-06-15T08:58:33.101656Z","shell.execute_reply.started":"2023-06-15T08:58:32.697606Z","shell.execute_reply":"2023-06-15T08:58:33.100486Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[array([[-1263.93280085,    46.07358725,   -29.22011048, ...,\n            24.80204235,   -41.89991013,    49.55471556],\n        [-1252.38154556,    43.67360874,   -30.36696877, ...,\n            26.68294346,   -42.92789906,    49.74477124],\n        [-1246.12120403,    38.57600417,   -25.74122791, ...,\n            28.71357077,   -41.89060294,    51.61496565],\n        ...,\n        [-1244.30515445,    26.22819326,   -27.85503784, ...,\n            20.16867726,   -16.24373551,    44.98726026],\n        [-1250.79415722,    23.76824719,   -24.83471839, ...,\n            15.91962871,   -18.2842161 ,    43.60716106],\n        [-1277.24219162,    17.25217179,   -17.74938543, ...,\n            12.45879396,   -19.85782639,    39.0074966 ]]),\n array([[91.18466027, 91.18466027, 91.18466027, ...,  5.38965364,\n          5.38965364,  5.38965364],\n        [91.21810168, 91.21810168, 91.21810168, ...,  5.39391131,\n          5.39391131,  5.39391131],\n        [90.90092665, 90.90092665, 90.90092665, ...,  5.51596725,\n          5.51596725,  5.51596725],\n        ...,\n        [84.63236726, 84.63236726, 84.63236726, ...,  7.25848691,\n          7.25848691,  7.25848691],\n        [85.36072781, 85.36072781, 85.36072781, ...,  6.58877517,\n          6.58877517,  6.58877517],\n        [86.97907588, 86.97907588, 86.97907588, ...,  5.85032787,\n          5.85032787,  5.85032787]]),\n array([[-72.05217231, -72.05217231, -72.05217231, ...,  -3.36588606,\n          -3.36588606,  -3.36588606],\n        [-71.20272593, -71.20272593, -71.20272593, ...,  -2.93311716,\n          -2.93311716,  -2.93311716],\n        [-71.04741629, -71.04741629, -71.04741629, ...,  -2.63075269,\n          -2.63075269,  -2.63075269],\n        ...,\n        [-75.25622573, -75.25622573, -75.25622573, ...,  -1.40232271,\n          -1.40232271,  -1.40232271],\n        [-75.62388822, -75.62388822, -75.62388822, ...,  -1.52234635,\n          -1.52234635,  -1.52234635],\n        [-77.15240551, -77.15240551, -77.15240551, ...,  -1.85402061,\n          -1.85402061,  -1.85402061]])]"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Build DataFrame**","metadata":{}},{"cell_type":"code","source":"# build dataframe\nimport pandas as pd\n\n# parse through files\nimport os\n\n# get progress\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:33.103007Z","iopub.execute_input":"2023-06-15T08:58:33.103368Z","iopub.status.idle":"2023-06-15T08:58:33.109021Z","shell.execute_reply.started":"2023-06-15T08:58:33.103337Z","shell.execute_reply":"2023-06-15T08:58:33.107833Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# create data framesegment\ndata = pd.DataFrame(columns=['audio_path','subject','segment','mfcc','delta_mfcc','delta_delta_mfcc','gfcc','delta_gfcc','delta_delta_gfcc','cqcc','delta_cqcc','delta_delta_cqcc','ad_or_not'])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:33.110626Z","iopub.execute_input":"2023-06-15T08:58:33.111006Z","iopub.status.idle":"2023-06-15T08:58:33.129045Z","shell.execute_reply.started":"2023-06-15T08:58:33.110976Z","shell.execute_reply":"2023-06-15T08:58:33.127913Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:33.134160Z","iopub.execute_input":"2023-06-15T08:58:33.134999Z","iopub.status.idle":"2023-06-15T08:58:33.163017Z","shell.execute_reply.started":"2023-06-15T08:58:33.134906Z","shell.execute_reply":"2023-06-15T08:58:33.161579Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 0 entries\nData columns (total 13 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   audio_path        0 non-null      object\n 1   subject           0 non-null      object\n 2   segment           0 non-null      object\n 3   mfcc              0 non-null      object\n 4   delta_mfcc        0 non-null      object\n 5   delta_delta_mfcc  0 non-null      object\n 6   gfcc              0 non-null      object\n 7   delta_gfcc        0 non-null      object\n 8   delta_delta_gfcc  0 non-null      object\n 9   cqcc              0 non-null      object\n 10  delta_cqcc        0 non-null      object\n 11  delta_delta_cqcc  0 non-null      object\n 12  ad_or_not         0 non-null      object\ndtypes: object(13)\nmemory usage: 0.0+ bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"# dataframe cols\n# path, subject ,segment , mfcc_3d, ad\n\ndir_path = '/kaggle/input/dementia-audio-classification'\nfiles = os.listdir(dir_path)\ncount = 0\n\nfor file in tqdm(files):\n    \n    elems = []\n    \n    audio_path = os.path.join(dir_path,file)\n    elems.append(audio_path)\n    \n    parts = file.split('_')\n    \n    subject = parts[1]\n    elems.append(subject)\n    \n    segment = parts[2]\n    elems.append(segment)\n    \n    # add mfcc's\n    mfcc_3d = extract_3d_mfcc(audio_path)\n    # elems.append(mfcc_3d)\n    elems.append(mfcc_3d[0])\n    elems.append(mfcc_3d[1])\n    elems.append(mfcc_3d[2])\n    \n    # add gfcc's\n    gfcc_3d = extract_3d_gfcc(audio_path)\n    # elems.append(gfcc_3d)\n    elems.append(gfcc_3d[0])\n    elems.append(gfcc_3d[1])\n    elems.append(gfcc_3d[2])\n    \n    # add cqcc's\n    cqcc_3d = extract_3d_cqcc(audio_path)\n    # elems.append(cqcc_3d)\n    elems.append(cqcc_3d[0])\n    elems.append(cqcc_3d[1])\n    elems.append(cqcc_3d[2])\n     \n    is_ad = parts[3].split('.')[0]\n    if is_ad == 'ad':\n        ad_or_not = 1\n    elif is_ad == 'cn':\n        ad_or_not = 0\n    elems.append(ad_or_not)\n    \n    elems_ragged = np.asarray(elems,dtype= 'object')\n    \n    # print(elems)\n    \n    # add to data frame\n    leng = len(data)\n    data.loc[leng] = elems_ragged\n    \n    count += 1\n    if count%5 == 0:\n        print(count)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-15T08:58:33.164630Z","iopub.execute_input":"2023-06-15T08:58:33.165089Z","iopub.status.idle":"2023-06-15T09:03:47.947964Z","shell.execute_reply.started":"2023-06-15T08:58:33.165048Z","shell.execute_reply":"2023-06-15T09:03:47.946804Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/486 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033809c0526a49d2800ec52e34c5f457"}},"metadata":{}},{"name":"stdout","text":"5\n10\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n65\n70\n75\n80\n85\n90\n95\n100\n105\n110\n115\n120\n125\n130\n135\n140\n145\n150\n155\n160\n165\n170\n175\n180\n185\n190\n195\n200\n205\n210\n215\n220\n225\n230\n235\n240\n245\n250\n255\n260\n265\n270\n275\n280\n285\n290\n295\n300\n305\n310\n315\n320\n325\n330\n335\n340\n345\n350\n355\n360\n365\n370\n375\n380\n385\n390\n395\n400\n405\n410\n415\n420\n425\n430\n435\n440\n445\n450\n455\n460\n465\n470\n475\n480\n485\n","output_type":"stream"}]},{"cell_type":"code","source":"data.to_csv('3d-features-all-ceps-arrs.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:47.949766Z","iopub.execute_input":"2023-06-15T09:03:47.950904Z","iopub.status.idle":"2023-06-15T09:03:49.665780Z","shell.execute_reply.started":"2023-06-15T09:03:47.950859Z","shell.execute_reply":"2023-06-15T09:03:49.664889Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"> refer https://superkogito.github.io/spafe/features/_features.html","metadata":{}},{"cell_type":"markdown","source":"## **Build a 3D CNN - mfcc**","metadata":{}},{"cell_type":"markdown","source":"## **Data Preparation**","metadata":{}},{"cell_type":"code","source":"data_1 = data.copy()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:49.667256Z","iopub.execute_input":"2023-06-15T09:03:49.667961Z","iopub.status.idle":"2023-06-15T09:03:49.673039Z","shell.execute_reply.started":"2023-06-15T09:03:49.667926Z","shell.execute_reply":"2023-06-15T09:03:49.672150Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### **Stacked MFCC**","metadata":{}},{"cell_type":"code","source":"# stack MFCC, del-MFCC , del-del-mfcc\nmfcc_stcked_1 = np.stack((data.loc[0,'mfcc'],data.loc[0,'delta_mfcc'],data.loc[0,'delta_delta_mfcc']))\nprint(mfcc_stcked_1.shape)\n\n# we have 2003 window frames\n# for each frame, we extract 20 ceps\n# to maintain that temporal feature, first column shud be => ceps of first frame, sec col is => ceps of second window frame\n# in the data we have, mfcc => first row is - ceps of first frame, sec row is - ceps of sec frame\n# so we find the transpose\n# then we stack\n\nmfcc_lyr_1 = np.transpose(data.loc[0,'mfcc'])\nmfcc_lyr_2 = np.transpose(data.loc[0,'delta_mfcc'])\nmfcc_lyr_3 = np.transpose(data.loc[0,'delta_delta_mfcc'])\nmfcc_stcked_2 = np.stack((mfcc_lyr_1,mfcc_lyr_2,mfcc_lyr_3))\nprint(mfcc_stcked_2.shape)\nprint(mfcc_stcked_2[:,:,:2].shape)\n\n# remember - \n# first dimension is depth - num of blocks stacked\n# second dimension is rows \n# third dimension is cols\n\n# so mfcc_stcked_2[:,:,2] means\n# select all_blocks + all_rows +  first_2_cols\n# which gives dimension of - (3,20,2) - vertically slicing cake","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:49.674612Z","iopub.execute_input":"2023-06-15T09:03:49.675253Z","iopub.status.idle":"2023-06-15T09:03:49.689803Z","shell.execute_reply.started":"2023-06-15T09:03:49.675221Z","shell.execute_reply":"2023-06-15T09:03:49.688554Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(3, 2003, 20)\n(3, 20, 2003)\n(3, 20, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"stcked_mfcc = []\nlabels = []\nfor elem in range(len(data_1)):    \n    mfcc_lyr_1 = np.transpose(data.loc[elem,'mfcc'])\n    mfcc_lyr_2 = np.transpose(data.loc[elem,'delta_mfcc'])\n    mfcc_lyr_3 = np.transpose(data.loc[elem,'delta_delta_mfcc'])\n    mfcc_stcked = np.stack((mfcc_lyr_1,mfcc_lyr_2,mfcc_lyr_3))\n    stcked_mfcc.append(mfcc_stcked)\n    labels.append(data.loc[elem,'ad_or_not'])\n    \n#     if elem%10 == 0:\n#         print(elem)\n\nprint(len(stcked_mfcc))\nprint(len(labels))\nprint(stcked_mfcc[0].shape)\nprint(labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:49.691749Z","iopub.execute_input":"2023-06-15T09:03:49.692698Z","iopub.status.idle":"2023-06-15T09:03:50.389614Z","shell.execute_reply.started":"2023-06-15T09:03:49.692652Z","shell.execute_reply":"2023-06-15T09:03:50.388471Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"486\n486\n(3, 20, 2003)\n1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Stacked GFCC**","metadata":{}},{"cell_type":"code","source":"stcked_gfcc = []\nlabels = []\nfor elem in range(len(data_1)):    \n    gfcc_lyr_1 = np.transpose(data.loc[elem,'gfcc'])\n    gfcc_lyr_2 = np.transpose(data.loc[elem,'delta_gfcc'])\n    gfcc_lyr_3 = np.transpose(data.loc[elem,'delta_delta_gfcc'])\n    gfcc_stcked = np.stack((gfcc_lyr_1,gfcc_lyr_2,gfcc_lyr_3))\n    stcked_gfcc.append(gfcc_stcked)\n    labels.append(data.loc[elem,'ad_or_not'])\n    \n#     if elem%10 == 0:\n#         print(elem)\n\nprint(len(stcked_gfcc))\nprint(len(labels))\nprint(stcked_gfcc[0].shape)\nprint(labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:50.391022Z","iopub.execute_input":"2023-06-15T09:03:50.392642Z","iopub.status.idle":"2023-06-15T09:03:51.076197Z","shell.execute_reply.started":"2023-06-15T09:03:50.392568Z","shell.execute_reply":"2023-06-15T09:03:51.075289Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"486\n486\n(3, 20, 2003)\n1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Stacked CQCC**","metadata":{}},{"cell_type":"code","source":"stcked_cqcc = []\nlabels = []\nfor elem in range(len(data_1)):    \n    cqcc_lyr_1 = np.transpose(data.loc[elem,'cqcc'])\n    cqcc_lyr_2 = np.transpose(data.loc[elem,'delta_cqcc'])\n    cqcc_lyr_3 = np.transpose(data.loc[elem,'delta_delta_cqcc'])\n    cqcc_stcked = np.stack((cqcc_lyr_1,cqcc_lyr_2,cqcc_lyr_3))\n    stcked_cqcc.append(cqcc_stcked)\n    labels.append(data.loc[elem,'ad_or_not'])\n    \n#     if elem%10 == 0:\n#         print(elem)\n\nprint(len(stcked_cqcc))\nprint(len(labels))\nprint(stcked_cqcc[0].shape)\nprint(labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:51.077574Z","iopub.execute_input":"2023-06-15T09:03:51.078735Z","iopub.status.idle":"2023-06-15T09:03:51.127759Z","shell.execute_reply.started":"2023-06-15T09:03:51.078691Z","shell.execute_reply":"2023-06-15T09:03:51.126444Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"486\n486\n(3, 20, 66)\n1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Build 3d-mfcc blocks for each audio sample**","metadata":{}},{"cell_type":"markdown","source":"### **Split data into train and test**\n* train:test is 70:30","metadata":{}},{"cell_type":"code","source":"data.ad_or_not.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:51.129290Z","iopub.execute_input":"2023-06-15T09:03:51.129760Z","iopub.status.idle":"2023-06-15T09:03:51.139173Z","shell.execute_reply.started":"2023-06-15T09:03:51.129720Z","shell.execute_reply":"2023-06-15T09:03:51.137920Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"1    283\n0    203\nName: ad_or_not, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_mfcc_train,x_mfcc_test,y_mfcc_train,y_mfcc_test = train_test_split(stcked_mfcc,labels,train_size = 0.7, random_state = 10)\n\nx_gfcc_train,x_gfcc_test,y_gfcc_train,y_gfcc_test = train_test_split(stcked_gfcc,labels,train_size = 0.7, random_state = 10)\n\nx_cqcc_train,x_cqcc_test,y_cqcc_train,y_cqcc_test = train_test_split(stcked_cqcc,labels,train_size = 0.7, random_state = 10)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:51.141102Z","iopub.execute_input":"2023-06-15T09:03:51.142096Z","iopub.status.idle":"2023-06-15T09:03:51.313626Z","shell.execute_reply.started":"2023-06-15T09:03:51.142051Z","shell.execute_reply":"2023-06-15T09:03:51.312424Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(len(x_mfcc_train),len(x_gfcc_train),len(x_cqcc_train))\nprint(len(y_mfcc_train),len(y_gfcc_train),len(y_cqcc_train))\nprint(len(y_mfcc_test),len(y_gfcc_test),len(y_cqcc_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:51.315282Z","iopub.execute_input":"2023-06-15T09:03:51.315751Z","iopub.status.idle":"2023-06-15T09:03:51.322784Z","shell.execute_reply.started":"2023-06-15T09:03:51.315709Z","shell.execute_reply":"2023-06-15T09:03:51.321724Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"340 340 340\n340 340 340\n146 146 146\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Value distribution in train and test**","metadata":{}},{"cell_type":"markdown","source":"### **Building model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:51.324157Z","iopub.execute_input":"2023-06-15T09:03:51.324587Z","iopub.status.idle":"2023-06-15T09:03:59.901310Z","shell.execute_reply.started":"2023-06-15T09:03:51.324550Z","shell.execute_reply":"2023-06-15T09:03:59.900095Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* input_shape =(4, 28, 28, 28, 1)\n* The inputs are 28x28x28 volumes with a single channel, and the\n* batch size is 4","metadata":{}},{"cell_type":"markdown","source":"## **Model-1 for MFCC**","metadata":{}},{"cell_type":"code","source":"# building model - mfcc\nmodel_1 = Sequential()\nmodel_1.add(layers.Conv3D(filters = 32,kernel_size =(3,3,3),activation = 'relu',input_shape = (3,20,2003,1),bias_initializer = Constant(0.01)))\nmodel_1.add(layers.Conv3D(32,(1,3,3),activation = 'relu',bias_initializer = Constant(0.01)))\nmodel_1.add(layers.MaxPooling3D((1,2,2)))\nmodel_1.add(layers.Conv3D(64,(1,3,3),activation = 'relu'))\nmodel_1.add(layers.Conv3D(64,(1,2,2),activation = 'relu'))\nmodel_1.add(layers.MaxPooling3D((1,2,2)))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Flatten())\nmodel_1.add(layers.Dense(256,'relu'))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Dense(128,'relu'))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Dense(2,'softmax')) # 2 outputs\nmodel_1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:03:59.902862Z","iopub.execute_input":"2023-06-15T09:03:59.904562Z","iopub.status.idle":"2023-06-15T09:04:00.494912Z","shell.execute_reply.started":"2023-06-15T09:03:59.904489Z","shell.execute_reply":"2023-06-15T09:04:00.493636Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv3d (Conv3D)             (None, 1, 18, 2001, 32)   896       \n                                                                 \n conv3d_1 (Conv3D)           (None, 1, 16, 1999, 32)   9248      \n                                                                 \n max_pooling3d (MaxPooling3D  (None, 1, 8, 999, 32)    0         \n )                                                               \n                                                                 \n conv3d_2 (Conv3D)           (None, 1, 6, 997, 64)     18496     \n                                                                 \n conv3d_3 (Conv3D)           (None, 1, 5, 996, 64)     16448     \n                                                                 \n max_pooling3d_1 (MaxPooling  (None, 1, 2, 498, 64)    0         \n 3D)                                                             \n                                                                 \n batch_normalization (BatchN  (None, 1, 2, 498, 64)    256       \n ormalization)                                                   \n                                                                 \n flatten (Flatten)           (None, 63744)             0         \n                                                                 \n dense (Dense)               (None, 256)               16318720  \n                                                                 \n batch_normalization_1 (Batc  (None, 256)              1024      \n hNormalization)                                                 \n                                                                 \n dense_1 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_2 (Batc  (None, 128)              512       \n hNormalization)                                                 \n                                                                 \n dense_2 (Dense)             (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 16,398,754\nTrainable params: 16,397,858\nNon-trainable params: 896\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Model-2 for CQCC**","metadata":{}},{"cell_type":"code","source":"# building model - gfcc,mfcc\nmodel_2 = Sequential()\nmodel_2.add(layers.Conv3D(filters = 32,kernel_size =(3,3,3),activation = 'relu',input_shape = (3,20,66,1),bias_initializer = Constant(0.01)))\nmodel_2.add(layers.Conv3D(32,(1,3,3),activation = 'relu',bias_initializer = Constant(0.01)))\nmodel_2.add(layers.MaxPooling3D((1,2,2)))\nmodel_2.add(layers.Conv3D(64,(1,3,3),activation = 'relu'))\nmodel_2.add(layers.Conv3D(64,(1,2,2),activation = 'relu'))\nmodel_2.add(layers.MaxPooling3D((1,2,2)))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Flatten())\nmodel_2.add(layers.Dense(256,'relu'))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Dense(128,'relu'))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Dense(2,'softmax')) # 2 outputs\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:00.496374Z","iopub.execute_input":"2023-06-15T09:04:00.496760Z","iopub.status.idle":"2023-06-15T09:04:00.734491Z","shell.execute_reply.started":"2023-06-15T09:04:00.496728Z","shell.execute_reply":"2023-06-15T09:04:00.731966Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv3d_4 (Conv3D)           (None, 1, 18, 64, 32)     896       \n                                                                 \n conv3d_5 (Conv3D)           (None, 1, 16, 62, 32)     9248      \n                                                                 \n max_pooling3d_2 (MaxPooling  (None, 1, 8, 31, 32)     0         \n 3D)                                                             \n                                                                 \n conv3d_6 (Conv3D)           (None, 1, 6, 29, 64)      18496     \n                                                                 \n conv3d_7 (Conv3D)           (None, 1, 5, 28, 64)      16448     \n                                                                 \n max_pooling3d_3 (MaxPooling  (None, 1, 2, 14, 64)     0         \n 3D)                                                             \n                                                                 \n batch_normalization_3 (Batc  (None, 1, 2, 14, 64)     256       \n hNormalization)                                                 \n                                                                 \n flatten_1 (Flatten)         (None, 1792)              0         \n                                                                 \n dense_3 (Dense)             (None, 256)               459008    \n                                                                 \n batch_normalization_4 (Batc  (None, 256)              1024      \n hNormalization)                                                 \n                                                                 \n dense_4 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_5 (Batc  (None, 128)              512       \n hNormalization)                                                 \n                                                                 \n dense_5 (Dense)             (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 539,042\nTrainable params: 538,146\nNon-trainable params: 896\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Model-3 for GFCC**","metadata":{}},{"cell_type":"code","source":"# building model - gfcc\nmodel_3 = Sequential()\nmodel_3.add(layers.Conv3D(filters = 32,kernel_size =(3,3,3),activation = 'relu',input_shape = (3,20,2003,1),bias_initializer = Constant(0.01)))\nmodel_3.add(layers.Conv3D(32,(1,3,3),activation = 'relu',bias_initializer = Constant(0.01)))\nmodel_3.add(layers.MaxPooling3D((1,2,2)))\nmodel_3.add(layers.Conv3D(64,(1,3,3),activation = 'relu'))\nmodel_3.add(layers.Conv3D(64,(1,2,2),activation = 'relu'))\nmodel_3.add(layers.MaxPooling3D((1,2,2)))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Flatten())\nmodel_3.add(layers.Dense(256,'relu'))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Dense(128,'relu'))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Dense(2,'softmax')) # 2 outputs\nmodel_3.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:00.736418Z","iopub.execute_input":"2023-06-15T09:04:00.737309Z","iopub.status.idle":"2023-06-15T09:04:01.107424Z","shell.execute_reply.started":"2023-06-15T09:04:00.737261Z","shell.execute_reply":"2023-06-15T09:04:01.106820Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv3d_8 (Conv3D)           (None, 1, 18, 2001, 32)   896       \n                                                                 \n conv3d_9 (Conv3D)           (None, 1, 16, 1999, 32)   9248      \n                                                                 \n max_pooling3d_4 (MaxPooling  (None, 1, 8, 999, 32)    0         \n 3D)                                                             \n                                                                 \n conv3d_10 (Conv3D)          (None, 1, 6, 997, 64)     18496     \n                                                                 \n conv3d_11 (Conv3D)          (None, 1, 5, 996, 64)     16448     \n                                                                 \n max_pooling3d_5 (MaxPooling  (None, 1, 2, 498, 64)    0         \n 3D)                                                             \n                                                                 \n batch_normalization_6 (Batc  (None, 1, 2, 498, 64)    256       \n hNormalization)                                                 \n                                                                 \n flatten_2 (Flatten)         (None, 63744)             0         \n                                                                 \n dense_6 (Dense)             (None, 256)               16318720  \n                                                                 \n batch_normalization_7 (Batc  (None, 256)              1024      \n hNormalization)                                                 \n                                                                 \n dense_7 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_8 (Batc  (None, 128)              512       \n hNormalization)                                                 \n                                                                 \n dense_8 (Dense)             (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 16,398,754\nTrainable params: 16,397,858\nNon-trainable params: 896\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* when convolved with filter - (s,s,s) on input volume - (a,b,c) => output volume is - ( a-(s-1) , b-(s-1) , c-(s-1) ) \n* lets say filter of dim (3,3,3) is applied on (3,20,2003 ) => output dim is (1,18,2001)\n* if 32 filters are applied => ouput from each is stacked => final output dimension = ( 32,18,2001 )\n* But if this is passed to next convolution layer and it has a filter of (3,3,3), convolution is performed separately on each depth slice of input volume","metadata":{}},{"cell_type":"markdown","source":"* if few rows are left out in pooling operation, they are discarded from output\n* if strides are not specified, strides - pool size => non-overlapping windows are pooled","metadata":{}},{"cell_type":"markdown","source":"* dropout is generally less effective at regularizing convolutional layers.\n* try batch normaliztion","metadata":{}},{"cell_type":"markdown","source":"### **Training 3d CNN - MFCC**","metadata":{}},{"cell_type":"markdown","source":"* Adam as the optimizer\n* Categorical cross-entropy as the loss function\n* accuracy as the loss metric for training\n* Earlystopping callback","metadata":{}},{"cell_type":"markdown","source":"#### **Compile model**","metadata":{}},{"cell_type":"code","source":"# mfcc\nmodel_1.compile(\n    optimizer = Adam(learning_rate=0.001),\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n             )","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:01.108332Z","iopub.execute_input":"2023-06-15T09:04:01.108688Z","iopub.status.idle":"2023-06-15T09:04:01.137037Z","shell.execute_reply.started":"2023-06-15T09:04:01.108658Z","shell.execute_reply":"2023-06-15T09:04:01.135851Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# cqcc\nmodel_2.compile(\n    optimizer = Adam(learning_rate=0.001),\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n             )","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:01.138815Z","iopub.execute_input":"2023-06-15T09:04:01.139161Z","iopub.status.idle":"2023-06-15T09:04:01.154176Z","shell.execute_reply.started":"2023-06-15T09:04:01.139132Z","shell.execute_reply":"2023-06-15T09:04:01.153265Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# gfcc\nmodel_3.compile(\n    optimizer = Adam(learning_rate=0.001),\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n             )","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:01.155623Z","iopub.execute_input":"2023-06-15T09:04:01.156631Z","iopub.status.idle":"2023-06-15T09:04:01.171184Z","shell.execute_reply.started":"2023-06-15T09:04:01.156596Z","shell.execute_reply":"2023-06-15T09:04:01.169844Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"#### **Data preprocessing - MFCC**","metadata":{}},{"cell_type":"code","source":"handling target data \ny_mfcc_train_new = to_categorical(y_mfcc_train,num_classes=2)\ny_mfcc_test_new = to_categorical(y_mfcc_test,num_classes=2)\nlen(y_mfcc_train_new)\n\n# handling input data\nx_mfcc_train_new_1 = np.array(x_mfcc_train)\nx_mfcc_train_new_2 = x_mfcc_train_new_1.reshape(x_mfcc_train_new_1.shape[0], 3, 20, 2003, 1)\n\nprint(type(x_mfcc_train_new_2))\nx_mfcc_train_new_2[0].shape\n\n\n# test\nx_mfcc_test_new_1 = np.array(x_mfcc_test)\nx_mfcc_test_new_2 = x_mfcc_test_new_1.reshape(x_mfcc_test_new_1.shape[0], 3, 20, 2003, 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:01.176397Z","iopub.execute_input":"2023-06-15T09:04:01.176848Z","iopub.status.idle":"2023-06-15T09:04:01.576271Z","shell.execute_reply.started":"2023-06-15T09:04:01.176812Z","shell.execute_reply":"2023-06-15T09:04:01.574634Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Data preprocessing - GFCC**","metadata":{}},{"cell_type":"code","source":"# handling target data \ny_gfcc_train_new = to_categorical(y_gfcc_train,num_classes=2)\ny_gfcc_test_new = to_categorical(y_gfcc_test,num_classes=2)\nlen(y_gfcc_train_new)\n\n# handling input data\nx_gfcc_train_new_1 = np.array(x_gfcc_train)\nx_gfcc_train_new_2 = x_gfcc_train_new_1.reshape(x_gfcc_train_new_1.shape[0], 3, 20, 2003, 1)\n\nprint(type(x_gfcc_train_new_2))\nx_gfcc_train_new_2[0].shape\n\n\n# test\nx_gfcc_test_new_1 = np.array(x_gfcc_test)\nx_gfcc_test_new_2 = x_gfcc_test_new_1.reshape(x_gfcc_test_new_1.shape[0], 3, 20, 2003, 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:01.577849Z","iopub.execute_input":"2023-06-15T09:04:01.578907Z","iopub.status.idle":"2023-06-15T09:04:01.999254Z","shell.execute_reply.started":"2023-06-15T09:04:01.578862Z","shell.execute_reply":"2023-06-15T09:04:01.997849Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **Data preprocessing - CQCC**","metadata":{}},{"cell_type":"code","source":"# handling target data \ny_cqcc_train_new = to_categorical(y_cqcc_train,num_classes=2)\ny_cqcc_test_new = to_categorical(y_cqcc_test,num_classes=2)\nlen(y_cqcc_train_new)\n\n# handling input data\nx_cqcc_train_new_1 = np.array(x_cqcc_train)\nx_cqcc_train_new_2 = x_cqcc_train_new_1.reshape(x_cqcc_train_new_1.shape[0], 3, 20, 66, 1)\n\nprint(type(x_cqcc_train_new_2))\nx_cqcc_train_new_2[0].shape\n\n\n# test\nx_cqcc_test_new_1 = np.array(x_cqcc_test)\nx_cqcc_test_new_2 = x_cqcc_test_new_1.reshape(x_cqcc_test_new_1.shape[0], 3, 20, 66, 1)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:02.000777Z","iopub.execute_input":"2023-06-15T09:04:02.001129Z","iopub.status.idle":"2023-06-15T09:04:02.025803Z","shell.execute_reply.started":"2023-06-15T09:04:02.001101Z","shell.execute_reply":"2023-06-15T09:04:02.024578Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **Fit Model**","metadata":{}},{"cell_type":"code","source":"# mfcc\nmodel_1.fit(x_mfcc_train_new_2,y_mfcc_train_new,epochs = 200, verbose = 1,validation_data = (x_mfcc_test_new_2,y_mfcc_test_new),callbacks = [EarlyStopping(patience=15)])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:04:02.027249Z","iopub.execute_input":"2023-06-15T09:04:02.028300Z","iopub.status.idle":"2023-06-15T09:32:58.202863Z","shell.execute_reply.started":"2023-06-15T09:04:02.028259Z","shell.execute_reply":"2023-06-15T09:32:58.201979Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/200\n11/11 [==============================] - 82s 7s/step - loss: 0.9714 - accuracy: 0.5971 - val_loss: 2.0096 - val_accuracy: 0.3493\nEpoch 2/200\n11/11 [==============================] - 77s 7s/step - loss: 0.3309 - accuracy: 0.8765 - val_loss: 4.2006 - val_accuracy: 0.6027\nEpoch 3/200\n11/11 [==============================] - 76s 7s/step - loss: 0.1303 - accuracy: 0.9794 - val_loss: 2.6455 - val_accuracy: 0.6027\nEpoch 4/200\n11/11 [==============================] - 76s 7s/step - loss: 0.0512 - accuracy: 0.9971 - val_loss: 3.8720 - val_accuracy: 0.6027\nEpoch 5/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0424 - accuracy: 0.9971 - val_loss: 2.3386 - val_accuracy: 0.6027\nEpoch 6/200\n11/11 [==============================] - 76s 7s/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.6096\nEpoch 7/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.6712\nEpoch 8/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.6781\nEpoch 9/200\n11/11 [==============================] - 76s 7s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.6507\nEpoch 10/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.5685\nEpoch 11/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8376 - val_accuracy: 0.4110\nEpoch 12/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1400 - val_accuracy: 0.4041\nEpoch 13/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4572 - val_accuracy: 0.3973\nEpoch 14/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.9938 - val_accuracy: 0.4178\nEpoch 15/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0128 - val_accuracy: 0.4110\nEpoch 16/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3950 - val_accuracy: 0.4178\nEpoch 17/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9847 - val_accuracy: 0.3973\nEpoch 18/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.4275 - val_accuracy: 0.3973\nEpoch 19/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.3793 - val_accuracy: 0.3973\nEpoch 20/200\n11/11 [==============================] - 75s 7s/step - loss: 7.8212e-04 - accuracy: 1.0000 - val_loss: 3.5400 - val_accuracy: 0.3973\nEpoch 21/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.6212 - val_accuracy: 0.3973\nEpoch 22/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.7517 - val_accuracy: 0.3973\nEpoch 23/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 11.0378 - val_accuracy: 0.3973\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ac1e879a350>"},"metadata":{}}]},{"cell_type":"code","source":"# gfcc\nmodel_3.fit(x_gfcc_train_new_2,y_gfcc_train_new,epochs = 200, verbose = 1,validation_data = (x_gfcc_test_new_2,y_gfcc_test_new),callbacks = [EarlyStopping(patience=15)])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:32:58.207081Z","iopub.execute_input":"2023-06-15T09:32:58.207424Z","iopub.status.idle":"2023-06-15T09:53:14.774329Z","shell.execute_reply.started":"2023-06-15T09:32:58.207394Z","shell.execute_reply":"2023-06-15T09:53:14.773327Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/200\n11/11 [==============================] - 77s 7s/step - loss: 1.2255 - accuracy: 0.5265 - val_loss: 0.7540 - val_accuracy: 0.3973\nEpoch 2/200\n11/11 [==============================] - 74s 7s/step - loss: 0.4313 - accuracy: 0.8088 - val_loss: 4.3167 - val_accuracy: 0.3973\nEpoch 3/200\n11/11 [==============================] - 74s 7s/step - loss: 0.3160 - accuracy: 0.8559 - val_loss: 7.5919 - val_accuracy: 0.3973\nEpoch 4/200\n11/11 [==============================] - 74s 7s/step - loss: 0.2153 - accuracy: 0.9324 - val_loss: 9.7862 - val_accuracy: 0.3973\nEpoch 5/200\n11/11 [==============================] - 74s 7s/step - loss: 0.1383 - accuracy: 0.9588 - val_loss: 19.5914 - val_accuracy: 0.3973\nEpoch 7/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0863 - accuracy: 0.9882 - val_loss: 22.4848 - val_accuracy: 0.3973\nEpoch 8/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0866 - accuracy: 0.9853 - val_loss: 26.6471 - val_accuracy: 0.3973\nEpoch 9/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0933 - accuracy: 0.9706 - val_loss: 27.5430 - val_accuracy: 0.3973\nEpoch 10/200\n11/11 [==============================] - 73s 7s/step - loss: 0.0815 - accuracy: 0.9765 - val_loss: 55.1812 - val_accuracy: 0.3973\nEpoch 11/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0547 - accuracy: 0.9882 - val_loss: 94.8026 - val_accuracy: 0.3973\nEpoch 12/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0710 - accuracy: 0.9824 - val_loss: 77.8251 - val_accuracy: 0.3973\nEpoch 13/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0710 - accuracy: 0.9882 - val_loss: 74.4212 - val_accuracy: 0.3973\nEpoch 14/200\n11/11 [==============================] - 74s 7s/step - loss: 0.0496 - accuracy: 0.9882 - val_loss: 156.8431 - val_accuracy: 0.3973\nEpoch 15/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0963 - accuracy: 0.9676 - val_loss: 136.0529 - val_accuracy: 0.3973\nEpoch 16/200\n11/11 [==============================] - 75s 7s/step - loss: 0.0632 - accuracy: 0.9882 - val_loss: 216.5065 - val_accuracy: 0.3973\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ac1e81aa3e0>"},"metadata":{}}]},{"cell_type":"code","source":"# cqcc\nmodel_2.fit(x_cqcc_train_new_2,y_cqcc_train_new,epochs = 200, verbose = 1,validation_data = (x_cqcc_test_new_2,y_cqcc_test_new),callbacks = [EarlyStopping(patience=15)])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:53:14.778215Z","iopub.execute_input":"2023-06-15T09:53:14.780104Z","iopub.status.idle":"2023-06-15T09:55:51.795625Z","shell.execute_reply.started":"2023-06-15T09:53:14.780071Z","shell.execute_reply":"2023-06-15T09:55:51.794685Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/200\n11/11 [==============================] - 5s 259ms/step - loss: 1.0440 - accuracy: 0.5029 - val_loss: 5.7934 - val_accuracy: 0.6027\nEpoch 2/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.6177 - accuracy: 0.6559 - val_loss: 3.1118 - val_accuracy: 0.5890\nEpoch 3/200\n11/11 [==============================] - 3s 237ms/step - loss: 0.5882 - accuracy: 0.7000 - val_loss: 1.9760 - val_accuracy: 0.6027\nEpoch 4/200\n11/11 [==============================] - 3s 233ms/step - loss: 0.4307 - accuracy: 0.7853 - val_loss: 1.4873 - val_accuracy: 0.6027\nEpoch 5/200\n11/11 [==============================] - 3s 231ms/step - loss: 0.4044 - accuracy: 0.8382 - val_loss: 2.4701 - val_accuracy: 0.6027\nEpoch 6/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.3039 - accuracy: 0.8912 - val_loss: 3.3327 - val_accuracy: 0.6027\nEpoch 7/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.2592 - accuracy: 0.9118 - val_loss: 3.6056 - val_accuracy: 0.6027\nEpoch 8/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.2173 - accuracy: 0.9382 - val_loss: 2.4916 - val_accuracy: 0.6096\nEpoch 9/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.2158 - accuracy: 0.9265 - val_loss: 1.6437 - val_accuracy: 0.5890\nEpoch 10/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.2407 - accuracy: 0.9059 - val_loss: 1.4714 - val_accuracy: 0.6164\nEpoch 11/200\n11/11 [==============================] - 3s 253ms/step - loss: 0.2108 - accuracy: 0.9235 - val_loss: 1.4762 - val_accuracy: 0.6096\nEpoch 12/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.1590 - accuracy: 0.9529 - val_loss: 2.3056 - val_accuracy: 0.6096\nEpoch 13/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.1265 - accuracy: 0.9706 - val_loss: 2.3548 - val_accuracy: 0.6096\nEpoch 14/200\n11/11 [==============================] - 3s 233ms/step - loss: 0.0914 - accuracy: 0.9794 - val_loss: 1.5733 - val_accuracy: 0.6096\nEpoch 15/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.0664 - accuracy: 0.9912 - val_loss: 1.5147 - val_accuracy: 0.6233\nEpoch 16/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.1037 - accuracy: 0.9735 - val_loss: 1.2185 - val_accuracy: 0.5959\nEpoch 17/200\n11/11 [==============================] - 2s 228ms/step - loss: 0.0891 - accuracy: 0.9853 - val_loss: 1.1826 - val_accuracy: 0.6575\nEpoch 18/200\n11/11 [==============================] - 3s 236ms/step - loss: 0.0761 - accuracy: 0.9882 - val_loss: 1.2566 - val_accuracy: 0.5959\nEpoch 19/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 1.3554 - val_accuracy: 0.6164\nEpoch 20/200\n11/11 [==============================] - 2s 228ms/step - loss: 0.0649 - accuracy: 0.9794 - val_loss: 1.1952 - val_accuracy: 0.5753\nEpoch 21/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.0558 - accuracy: 0.9882 - val_loss: 1.2962 - val_accuracy: 0.5616\nEpoch 22/200\n11/11 [==============================] - 3s 233ms/step - loss: 0.0425 - accuracy: 0.9941 - val_loss: 1.6296 - val_accuracy: 0.5890\nEpoch 23/200\n11/11 [==============================] - 3s 249ms/step - loss: 0.0541 - accuracy: 0.9794 - val_loss: 1.7893 - val_accuracy: 0.6301\nEpoch 24/200\n11/11 [==============================] - 3s 236ms/step - loss: 0.0695 - accuracy: 0.9824 - val_loss: 1.7489 - val_accuracy: 0.5274\nEpoch 25/200\n11/11 [==============================] - 3s 231ms/step - loss: 0.1061 - accuracy: 0.9500 - val_loss: 1.9975 - val_accuracy: 0.5753\nEpoch 26/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.1115 - accuracy: 0.9647 - val_loss: 1.6610 - val_accuracy: 0.5205\nEpoch 27/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.1299 - accuracy: 0.9529 - val_loss: 1.2449 - val_accuracy: 0.5548\nEpoch 28/200\n11/11 [==============================] - 3s 231ms/step - loss: 0.0730 - accuracy: 0.9765 - val_loss: 1.6289 - val_accuracy: 0.4932\nEpoch 29/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.0548 - accuracy: 0.9824 - val_loss: 1.7527 - val_accuracy: 0.4932\nEpoch 30/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.0609 - accuracy: 0.9853 - val_loss: 2.1587 - val_accuracy: 0.4863\nEpoch 31/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.0542 - accuracy: 0.9824 - val_loss: 1.1742 - val_accuracy: 0.6096\nEpoch 32/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.0298 - accuracy: 0.9941 - val_loss: 1.4062 - val_accuracy: 0.5959\nEpoch 33/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.5137\nEpoch 34/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 1.9443 - val_accuracy: 0.5205\nEpoch 35/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.6342 - val_accuracy: 0.5205\nEpoch 36/200\n11/11 [==============================] - 3s 253ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7323 - val_accuracy: 0.5137\nEpoch 37/200\n11/11 [==============================] - 3s 228ms/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 2.0757 - val_accuracy: 0.4932\nEpoch 38/200\n11/11 [==============================] - 3s 238ms/step - loss: 0.0156 - accuracy: 0.9941 - val_loss: 2.0374 - val_accuracy: 0.5137\nEpoch 39/200\n11/11 [==============================] - 3s 234ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 1.8207 - val_accuracy: 0.5548\nEpoch 40/200\n11/11 [==============================] - 3s 232ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 2.2589 - val_accuracy: 0.6096\nEpoch 41/200\n11/11 [==============================] - 3s 233ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 2.4077 - val_accuracy: 0.6027\nEpoch 42/200\n11/11 [==============================] - 3s 230ms/step - loss: 0.0628 - accuracy: 0.9765 - val_loss: 2.2325 - val_accuracy: 0.5479\nEpoch 43/200\n11/11 [==============================] - 2s 227ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 1.7275 - val_accuracy: 0.5479\nEpoch 44/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.0343 - accuracy: 0.9853 - val_loss: 2.0806 - val_accuracy: 0.5890\nEpoch 45/200\n11/11 [==============================] - 3s 229ms/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 3.0658 - val_accuracy: 0.6027\nEpoch 46/200\n11/11 [==============================] - 3s 233ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 2.6071 - val_accuracy: 0.4795\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ac1d1afc4f0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Evaluating the model**","metadata":{}},{"cell_type":"code","source":"# mfcc\n_,acc = model_1.evaluate(x_mfcc_train_new_2,y_mfcc_train_new,verbose = 1)\n_,acc = model_1.evaluate(x_mfcc_test_new_2,y_mfcc_test_new,verbose = 1)\nprint('MFCC - training accuracy - '+ str(round(acc*100,2)) + '%' )\nprint('MFCC - testing accuracy - '+ str(round(acc*100,2)) + '%' )\n\n\n# cqcc\n_,acc = model_2.evaluate(x_cqcc_train_new_2,y_cqcc_train_new,verbose = 1)\n_,acc = model_2.evaluate(x_cqcc_test_new_2,y_cqcc_test_new,verbose = 1)\nprint('CQCC - training accuracy - '+ str(round(acc*100,2)) + '%' )\nprint('CQCC - testing accuracy - '+ str(round(acc*100,2)) + '%' )\n\n\n# gfcc\n_,acc = model_3.evaluate(x_gfcc_train_new_2,y_gfcc_train_new,verbose = 1)\n_,acc = model_3.evaluate(x_gfcc_test_new_2,y_gfcc_test_new,verbose = 1)\nprint('GFCC - training accuracy - '+ str(round(acc*100,2)) + '%' )\nprint('GFCC - testing accuracy - '+ str(round(acc*100,2)) + '%' )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:55:51.799432Z","iopub.execute_input":"2023-06-15T09:55:51.799828Z","iopub.status.idle":"2023-06-15T09:56:46.440252Z","shell.execute_reply.started":"2023-06-15T09:55:51.799797Z","shell.execute_reply":"2023-06-15T09:56:46.438726Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"11/11 [==============================] - 9s 830ms/step - loss: 9.4770 - accuracy: 0.4265\n5/5 [==============================] - 4s 815ms/step - loss: 11.0378 - accuracy: 0.3973\nMFCC - training accuracy - 39.73%\nMFCC - testing accuracy - 39.73%\n11/11 [==============================] - 0s 29ms/step - loss: 0.1227 - accuracy: 0.9706\n5/5 [==============================] - 0s 29ms/step - loss: 2.6071 - accuracy: 0.4795\nCQCC - training accuracy - 47.95%\nCQCC - testing accuracy - 47.95%\n11/11 [==============================] - 9s 805ms/step - loss: 205.6658 - accuracy: 0.4265\n5/5 [==============================] - 4s 744ms/step - loss: 216.5065 - accuracy: 0.3973\nGFCC - training accuracy - 39.73%\nGFCC - testing accuracy - 39.73%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. ### Great article on types of convolutions\n* https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215\n2. ### Maxpooling\n* https://towardsdatascience.com/understanding-convolutions-and-pooling-in-neural-networks-a-simple-explanation-885a2d78f211","metadata":{}},{"cell_type":"code","source":"2* 498*64","metadata":{"execution":{"iopub.status.busy":"2023-06-15T09:56:46.442817Z","iopub.execute_input":"2023-06-15T09:56:46.443569Z","iopub.status.idle":"2023-06-15T09:56:46.450814Z","shell.execute_reply.started":"2023-06-15T09:56:46.443522Z","shell.execute_reply":"2023-06-15T09:56:46.449699Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"63744"},"metadata":{}}]}]}